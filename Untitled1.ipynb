{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "0 acc_train_loss 10000.00 acc_train_error 90.80% test_error 90.10%\n",
      "1 acc_train_loss 7712.08 acc_train_error 88.30% test_error 90.10%\n",
      "2 acc_train_loss 6327.60 acc_train_error 88.30% test_error 90.10%\n",
      "3 acc_train_loss 5499.00 acc_train_error 88.30% test_error 90.10%\n",
      "4 acc_train_loss 4982.80 acc_train_error 88.30% test_error 90.10%\n",
      "5 acc_train_loss 4636.85 acc_train_error 88.30% test_error 90.10%\n",
      "6 acc_train_loss 4337.49 acc_train_error 88.30% test_error 90.10%\n",
      "7 acc_train_loss 3916.80 acc_train_error 88.30% test_error 90.10%\n",
      "8 acc_train_loss 3641.76 acc_train_error 88.30% test_error 90.10%\n",
      "9 acc_train_loss 3610.11 acc_train_error 88.30% test_error 90.10%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def sigma(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def dsigma(x):\n",
    "    return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "\n",
    "def relu(x):\n",
    "\tif x > 0:\n",
    "\t\treturn x\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def loss(v, t):\n",
    "    return (v - t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x\n",
    "    s1 = w1.mv(x0) + b1\n",
    "    x1 = sigma(s1)\n",
    "    s2 = w2.mv(x1) + b2\n",
    "    x2 = sigma(s2)\n",
    "\n",
    "    return x0, s1, x1, s2, x2\n",
    "\n",
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    x0 = x\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    dl_ds2 = dsigma(s2) * dl_dx2\n",
    "    dl_dx1 = w2.t().mv(dl_ds2)\n",
    "    dl_ds1 = dsigma(s1) * dl_dx1\n",
    "\n",
    "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
    "    dl_db2.add_(dl_ds2)\n",
    "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db1.add_(dl_ds1)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "train_input, train_target, test_input, test_target = prologue.load_data(one_hot_labels = True,\n",
    "                                                                        normalize = True)\n",
    "\n",
    "nb_classes = train_target.size(1)\n",
    "nb_train_samples = train_input.size(0)\n",
    "\n",
    "zeta = 0.90\n",
    "\n",
    "train_input = train_input * zeta\n",
    "test_input = test_input * zeta\n",
    "\n",
    "nb_hidden = 50\n",
    "eta = 1e-1 / nb_train_samples\n",
    "epsilon = 1e-6\n",
    "\n",
    "w1 = Tensor(nb_hidden, train_input.size(1)).normal_(0, epsilon)\n",
    "b1 = Tensor(nb_hidden).normal_(0, epsilon)\n",
    "w2 = Tensor(nb_classes, nb_hidden).normal_(0, epsilon)\n",
    "b2 = Tensor(nb_classes).normal_(0, epsilon)\n",
    "\n",
    "dl_dw1 = Tensor(w1.size())\n",
    "dl_db1 = Tensor(b1.size())\n",
    "dl_dw2 = Tensor(w2.size())\n",
    "dl_db2 = Tensor(b2.size())\n",
    "\n",
    "for k in range(0, 10):\n",
    "\n",
    "    # Back-prop\n",
    "\n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "\n",
    "    dl_dw1.zero_()\n",
    "    dl_db1.zero_()\n",
    "    dl_dw2.zero_()\n",
    "    dl_db2.zero_()\n",
    "\n",
    "    for n in range(0, nb_train_samples):\n",
    "        x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, train_input[n])\n",
    "\n",
    "        pred = x2.max(0)[1][0]\n",
    "        if train_target[n, pred] < 0: nb_train_errors = nb_train_errors + 1\n",
    "        acc_loss = acc_loss + loss(x2, train_target[n])\n",
    "\n",
    "        backward_pass(w1, b1, w2, b2,\n",
    "                      train_target[n],\n",
    "                      x0, s1, x1, s2, x2,\n",
    "                      dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "\n",
    "    # Gradient step\n",
    "\n",
    "    w1 = w1 - eta * dl_dw1\n",
    "    b1 = b1 - eta * dl_db1\n",
    "    w2 = w2 - eta * dl_dw2\n",
    "    b2 = b2 - eta * dl_db2\n",
    "\n",
    "    # Test error\n",
    "\n",
    "    nb_test_errors = 0\n",
    "\n",
    "    for n in range(0, test_input.size(0)):\n",
    "        _, _, _, _, x2 = forward_pass(w1, b1, w2, b2, test_input[n])\n",
    "\n",
    "        pred = x2.max(0)[1][0]\n",
    "        if test_target[n, pred] < 0: nb_test_errors = nb_test_errors + 1\n",
    "\n",
    "    print('{:d} acc_train_loss {:.02f} acc_train_error {:.02f}% test_error {:.02f}%'\n",
    "          .format(k,\n",
    "                  acc_loss,\n",
    "                  (100 * nb_train_errors) / train_input.size(0),\n",
    "                  (100 * nb_test_errors) / test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "          ...             ⋱             ...          \n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "-0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "[torch.FloatTensor of size 1000x784]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "           ...             ⋱             ...          \n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " [torch.FloatTensor of size 1000x784], \n",
       "    -1    -1    -1  ...     -1    -1    -1\n",
       "     1    -1    -1  ...     -1    -1    -1\n",
       "    -1    -1    -1  ...     -1    -1    -1\n",
       "        ...          ⋱          ...       \n",
       "     1    -1    -1  ...     -1    -1    -1\n",
       "    -1    -1    -1  ...     -1    -1    -1\n",
       "    -1    -1    -1  ...     -1    -1    -1\n",
       " [torch.FloatTensor of size 1000x10], \n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       "           ...             ⋱             ...          \n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " -0.3782 -0.3782 -0.3782  ...  -0.3782 -0.3782 -0.3782\n",
       " [torch.FloatTensor of size 1000x784], \n",
       "    -1    -1    -1  ...      1    -1    -1\n",
       "    -1    -1     1  ...     -1    -1    -1\n",
       "    -1     1    -1  ...     -1    -1    -1\n",
       "        ...          ⋱          ...       \n",
       "     1    -1    -1  ...     -1    -1    -1\n",
       "    -1    -1    -1  ...     -1     1    -1\n",
       "    -1    -1    -1  ...     -1    -1     1\n",
       " [torch.FloatTensor of size 1000x10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
